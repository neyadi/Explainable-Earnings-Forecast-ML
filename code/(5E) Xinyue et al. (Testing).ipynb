{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e3168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74391fa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c03577",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/subsets.pkl', 'rb')\n",
    "subsets = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328875ce",
   "metadata": {},
   "source": [
    "### Add Relative Earnings Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e9947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ranks(group, col, num_ranks):\n",
    "    sorted_group = group.sort_values(col, ascending=False)\n",
    "    size = len(sorted_group)\n",
    "    rank_size = size // num_ranks\n",
    "    ranks = []\n",
    "\n",
    "    for rank in range(1, num_ranks + 1):\n",
    "        if rank != num_ranks:\n",
    "            ranks.extend([rank] * rank_size)\n",
    "        else:\n",
    "            ranks.extend([rank] * (size - len(ranks)))\n",
    "\n",
    "    sorted_group[col + '_rank'] = ranks\n",
    "    return sorted_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f741ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_rank(df, cols, num_ranks):\n",
    "    df_ranked = df.copy(deep=True)\n",
    "    for col in cols:\n",
    "        df_ranked = df_ranked.groupby('datacqtr').apply(lambda x: assign_ranks(x, col, num_ranks=num_ranks))\n",
    "        df_ranked = df_ranked.reset_index(drop=True)\n",
    "        df_ranked['_'.join(col.split('_')[:-1])+'_direction'] = df_ranked[f'{col}_rank'] - 1\n",
    "\n",
    "    df_ranked = df_ranked.drop(columns=[x for x in df_ranked.columns if '_rank' in x])\n",
    "    return df_ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52fea2a",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c77020",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_features = ['gvkey','datacqtr', 'cusip','tic', 'announcement_date','analyst_date',\n",
    "                'nq_eps_actual_direction','nq_eps_actual_change',\n",
    "                'nq_eps_predicted_mean_direction','nq_eps_predicted_mean_change',\n",
    "                'nq_eps_predicted_median_direction','nq_eps_predicted_median_change']\n",
    "\n",
    "columns_to_rank = ['nq_eps_actual_change','nq_eps_predicted_mean_change','nq_eps_predicted_median_change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb53bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {'datacqtr': [],'gvkey': [],'cusip':[],'tic':[], \n",
    "               'announcement_date':[], 'analyst_date':[],\n",
    "               'direction_pred':[],'value_pred':[],\n",
    "               'direction_actual': [],'value_actual': [], \n",
    "               'direction_analyst_mean': [],'value_analyst_mean': [],\n",
    "               'direction_analyst_median': [],'value_analyst_median': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb47fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'year': '2013', 'accuracy': 0.6304746918436926, 'f1': 0.6281976808084239}\n",
      "2 {'year': '2014', 'accuracy': 0.6279527559055118, 'f1': 0.6266438782845873}\n",
      "3 {'year': '2015', 'accuracy': 0.6274965164886205, 'f1': 0.6269269461772167}\n",
      "4 {'year': '2016', 'accuracy': 0.6281517211137908, 'f1': 0.626931439073262}\n",
      "5 {'year': '2017', 'accuracy': 0.6376061296334645, 'f1': 0.6356358953810233}\n",
      "6 {'year': '2018', 'accuracy': 0.6336437487616405, 'f1': 0.6334094589145207}\n",
      "7 {'year': '2019', 'accuracy': 0.6338162409454823, 'f1': 0.6329453498423747}\n",
      "1 {'year': '2013', 'accuracy': 0.43797534749541045, 'f1': 0.43124199854345663}\n",
      "2 {'year': '2014', 'accuracy': 0.42076771653543305, 'f1': 0.41260107716308836}\n",
      "3 {'year': '2015', 'accuracy': 0.4335810496980957, 'f1': 0.42433050587599}\n",
      "4 {'year': '2016', 'accuracy': 0.4170138127603596, 'f1': 0.40490887869467307}\n",
      "5 {'year': '2017', 'accuracy': 0.43466556222820457, 'f1': 0.4238637294370989}\n",
      "6 {'year': '2018', 'accuracy': 0.4374876164057856, 'f1': 0.4273533029055911}\n",
      "7 {'year': '2019', 'accuracy': 0.4412886008387343, 'f1': 0.42966758979346814}\n",
      "1 {'year': '2013', 'accuracy': 0.33648046157880934, 'f1': 0.32306111377280067}\n",
      "2 {'year': '2014', 'accuracy': 0.3248031496062992, 'f1': 0.31299019596748817}\n",
      "3 {'year': '2015', 'accuracy': 0.3237343241987924, 'f1': 0.31160842777564723}\n",
      "4 {'year': '2016', 'accuracy': 0.3203244902433677, 'f1': 0.3050058422052339}\n",
      "5 {'year': '2017', 'accuracy': 0.3334023607372127, 'f1': 0.31761100507491963}\n",
      "6 {'year': '2018', 'accuracy': 0.3293045373489201, 'f1': 0.31572029906967397}\n",
      "7 {'year': '2019', 'accuracy': 0.33473122378955394, 'f1': 0.3206821427703121}\n"
     ]
    }
   ],
   "source": [
    "for num_classes in [3,6,9]:\n",
    "    results = []\n",
    "    predictions_class = copy.deepcopy(predictions)\n",
    "    for i, year in enumerate(sorted(subsets.keys())):\n",
    "        # split into training and testing\n",
    "        df_train = subsets[year]['train']\n",
    "        df_test = subsets[year]['test']\n",
    "        \n",
    "        # rank target variables\n",
    "        df_train = df_rank(df_train, columns_to_rank, num_classes)\n",
    "        df_test = df_rank(df_test, columns_to_rank, num_classes)\n",
    "\n",
    "        # create train and test features\n",
    "        train_features = np.array(df_train.drop(non_features, axis = 1))\n",
    "        test_features = np.array(df_test.drop(non_features, axis = 1))\n",
    "\n",
    "        # create train and test labels\n",
    "        train_labels = np.array(df_train['nq_eps_actual_direction'])\n",
    "        test_labels = np.array(df_test['nq_eps_actual_direction'])\n",
    "\n",
    "        # train model\n",
    "        params = {\n",
    "            'objective': 'multiclass',\n",
    "            'num_class': num_classes,\n",
    "            'metric': 'multi_logloss',\n",
    "            'verbose': -1\n",
    "        }\n",
    "        train_data = lgb.Dataset(train_features, label=train_labels)\n",
    "        model = lgb.train(params, train_data)\n",
    "\n",
    "        # make predictions\n",
    "        cb_predict_proba = model.predict(test_features)\n",
    "        cb_predict = np.argmax(cb_predict_proba, axis=1)\n",
    "        cb_predict_proba = cb_predict_proba[:,0]\n",
    "        \n",
    "        # results \n",
    "        results.append({'year': year, \n",
    "                        'accuracy': accuracy_score(test_labels, cb_predict), \n",
    "                        'f1': f1_score(test_labels, cb_predict, average='macro')})\n",
    "        \n",
    "        predictions_class['direction_pred'] += list(cb_predict)\n",
    "        predictions_class['value_pred'] += list(cb_predict_proba)\n",
    "\n",
    "        predictions_class['direction_actual'] += list(test_labels)\n",
    "        predictions_class['value_actual'] += list(df_test['nq_eps_actual_change'])\n",
    "\n",
    "        predictions_class['direction_analyst_mean'] += list(df_test['nq_eps_predicted_mean_direction'])\n",
    "        predictions_class['value_analyst_mean'] += list(df_test['nq_eps_predicted_mean_change'])\n",
    "\n",
    "        predictions_class['direction_analyst_median'] += list(df_test['nq_eps_predicted_median_direction'])\n",
    "        predictions_class['value_analyst_median'] += list(df_test['nq_eps_predicted_median_change'])\n",
    "\n",
    "        predictions_class['datacqtr'] += list(df_test['datacqtr'])\n",
    "        predictions_class['gvkey'] += list(df_test['gvkey'])\n",
    "        predictions_class['cusip'] += list(df_test['cusip'])\n",
    "        predictions_class['tic'] += list(df_test['tic'])\n",
    "        predictions_class['announcement_date'] += list(df_test['announcement_date'])\n",
    "        predictions_class['analyst_date'] += list(df_test['analyst_date'])\n",
    "\n",
    "        print(i+1, results[-1])\n",
    "    \n",
    "    predictions_df = pd.DataFrame(predictions_class)\n",
    "    predictions_df.to_pickle(f'../results/xinyue_predictions_{num_classes}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
